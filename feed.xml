<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://sdaza.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sdaza.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-01-09T09:31:15+01:00</updated><id>https://sdaza.com/feed.xml</id><title type="html">blank</title><subtitle>Demography, Sociology, Simulation, Data Science A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.</subtitle><entry><title type="html">Extracting Zotero’s notes</title><link href="https://sdaza.com/blog/2021/zotero-notes/" rel="alternate" type="text/html" title="Extracting Zotero’s notes"/><published>2021-07-06T00:00:00+02:00</published><updated>2021-07-06T00:00:00+02:00</updated><id>https://sdaza.com/blog/2021/zotero-notes</id><content type="html" xml:base="https://sdaza.com/blog/2021/zotero-notes/"><![CDATA[<p>When reviewing the literature, it’s nice to have the notes linked to Zotero references. It would also be great to compare them systematically. The idea would be to have your notes in Zotero so that everyone in the group can access and edit them and create a data file to explore your notes using, for instance, text analysis techniques.</p> <p>This small package extracts notes from a collection and creates a CSV file that can be easily read using Excel. You only need to specify the collection ID. For instance, if the location of my collection is <code class="language-plaintext highlighter-rouge">https://www.zotero.org/groups/2406179/csic-echo/collections/M8N2VMAP</code>, the collection ID would be <code class="language-plaintext highlighter-rouge">M8N2VMAP</code>. We also need the Zotero API’s credentials.</p> <p>To create a clean CSV, notes’ headers would need a suitable separator. The default is <code class="language-plaintext highlighter-rouge">#</code>. In this case, the text between headings mustn’t include <code class="language-plaintext highlighter-rouge">#</code>. Below an example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Research question

Estimates interaction effects between PGS of obesity and cohorts using HRS.

# Data

HRS

# Methods

Uses a HLM whereby they estimate effects of age and cohorts while making the
intercepts and slopes a function of individual factors.
</code></pre></div></div> <h2 id="installation">Installation</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install git+https://github.com/sdaza/zotnote.git
</code></pre></div></div> <h2 id="credentials">Credentials</h2> <p>You can save your Zotero API credentials in a <code class="language-plaintext highlighter-rouge">config.py</code> and load them using <code class="language-plaintext highlighter-rouge">import config</code>:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">library_id = "0000000"</span>
<span class="s">api_key = "key"</span>
<span class="s">library_type = "group"</span>
</code></pre></div></div> <h2 id="example">Example</h2> <p>Let’s try to extract some notes and read them using Pandas:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">config</span>
<span class="kn">import</span> <span class="nn">zotnote</span> <span class="k">as</span> <span class="n">zn</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">zn</span><span class="p">.</span><span class="n">exportNotes</span><span class="p">(</span><span class="n">collection</span> <span class="o">=</span> <span class="s">"M8N2VMAP"</span><span class="p">,</span> 
    <span class="n">library_id</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">library_id</span><span class="p">,</span> <span class="n">api_key</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">api_key</span><span class="p">)</span></code></pre></figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Notes saved in zotero-notes.csv
</code></pre></div></div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"zotero-notes.csv"</span><span class="p">)</span></code></pre></figure> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>id</th> <th>citation</th> <th>tags</th> <th>title</th> <th>reviewer</th> <th>research_question</th> <th>model</th> <th>data</th> <th>methods</th> <th>conclusions</th> <th>the_good</th> <th>limitations</th> <th>results</th> <th>context</th> <th>next</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>4ESWAPZY</td> <td>van Dijk et al. 2015</td> <td>NaN</td> <td>Recent developments on the role of epigenetics...</td> <td>Elena</td> <td>Knowledge about epigenetic marks related to ob...</td> <td>Human and animal</td> <td>Review</td> <td>NaN</td> <td>NaN</td> <td>Good summary tables of studies carried out in ...</td> <td>So far, a causal role of epigenetics in the de...</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1</th> <td>5JNF33U8</td> <td>Fernandez-Twinn et al. 2019</td> <td>intrauterine effects, epigenetics</td> <td>Intrauterine programming of obesity and type 2...</td> <td>Elena</td> <td>Which are the relevant exposures related to th...</td> <td>Human and also murine models</td> <td>NaN</td> <td>NaN</td> <td>-          The main exposures involved: fetal ...</td> <td>NaN</td> <td>limited evidence for  a causal role for epigen...</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>S8FZS32L</td> <td>Ling 2019</td> <td>Elena</td> <td>Epigenetics in Human Obesity and Type 2 Diabetes</td> <td>Elena</td> <td>Summarizes epigenetic signatures from human ti...</td> <td>NaN</td> <td>Human</td> <td>Different large-scale methylation studies usin...</td> <td>NaN</td> <td>Also covers diet (methyl donnors) and epigenet...</td> <td>In epigenetic studies it’s important to unders...</td> <td>1) Evidence for DNA methylation sites that con...</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>QY3Y7V6X</td> <td>Sharp et al. 2017</td> <td>Must read</td> <td>Maternal BMI at the start of pregnancy and off...</td> <td>Elena</td> <td>Is maternal bmi related with changes in the of...</td> <td>NaN</td> <td>meta-analysis across 19 cohorts using 450k ill...</td> <td>2 models: primary análisis used continous bmi ...</td> <td>They found evicence for a causal intrauterine ...</td> <td>Large sample size n=7523. Strong confounder co...</td> <td>Effects sizes were very small, les tan a 0.15%...</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>5AMCHQMB</td> <td>Sulc et al. 2020</td> <td>NaN</td> <td>Quantification of the overall contribution of ...</td> <td>Sebastian</td> <td>Can we use a method to estimate GxE without me...</td> <td>NaN</td> <td>Simulation and application to complex traits f...</td> <td>Detect GxE based on the variance heterogeneity...</td> <td>NaN</td> <td>Interesting approach to GxE and GxG. The metho...</td> <td>The interaction effect estimates may depend to...</td> <td>Simulation results seem to show the method is ...</td> <td>GxE are challenging, E is not measured accurat...</td> <td>What would be the implications of these result...</td> </tr> <tr> <th>5</th> <td>U4MNK7QT</td> <td>Walter et al. 2016</td> <td>Genomics, HRS, GxE, BMI</td> <td>Association of a Genetic Risk Score With Body ...</td> <td>Sebastian</td> <td>Estimates interaction effects between PGS of o...</td> <td>NaN</td> <td>HRS</td> <td>Uses a HLM whereby they estimate effects of ag...</td> <td>NaN</td> <td>NaN</td> <td>Pays little attention to selection due to surv...</td> <td>NaN</td> <td>NaN</td> <td>Anything</td> </tr> <tr> <th>6</th> <td>RGDC9R9R</td> <td>Abadi et al. 2017</td> <td>Genomics, GxG, GxE, BMI</td> <td>Penetrance of Polygenic Obesity Susceptibility...</td> <td>Sebastian</td> <td>Are the effects of obesity-susceptibility loci...</td> <td>NaN</td> <td>Several studies, including the Framingham coho...</td> <td>Conditional quantile regression (CQR) to inves...</td> <td>NaN</td> <td>Interesting approach to GxE and GxG.</td> <td>European ancestry, how these results hold in d...</td> <td>Significant positive associations (adjusting f...</td> <td>The role of the individual and compound gene-e...</td> <td>What would be the implications of these result...</td> </tr> </tbody> </table> </div>]]></content><author><name>Sebastian Daza</name></author><category term="zotero"/><summary type="html"><![CDATA[How to extract zotero notes to CSV / Excel file]]></summary></entry><entry><title type="html">From database to CSV using Anylogic</title><link href="https://sdaza.com/blog/2020/anylogic-database/" rel="alternate" type="text/html" title="From database to CSV using Anylogic"/><published>2020-11-03T00:00:00+01:00</published><updated>2020-11-03T00:00:00+01:00</updated><id>https://sdaza.com/blog/2020/anylogic-database</id><content type="html" xml:base="https://sdaza.com/blog/2020/anylogic-database/"><![CDATA[<p>When running a parameter variation experiment, that is, simulating over several iterations and replicates using parallelization, we usually need to collect a huge amount of data and have them in a format that then we can process using Python or R.</p> <p>The best way to do this in Anylogic would be using a database and then export, read, or connect to the database to process simulation results (although, see the section <strong>update</strong> below). We can do that easily in Anylogic. Every time an experiment finishes, we can export the data (from a database) to an Excel file manually.</p> <p>The issue with Excel files is, on the one hand, they are Excel files, and on the other, they are not suitable for big data (more than 1 million rows). We can create a function to save all the simulation tables into an Excel file as our experiment finishes. However, we will still have the limit-of-rows limitation (check the Anylogic file linked below for a function to create Excel files from a database).</p> <p>Here I follow a different approach by exporting an Anylogic database table to a CSV file within Java. The general setup using Anylogic PLE 8.6 would be:</p> <ul> <li>Create the databases you need for your experiment, and be sure you add the columns iteration and replicate.</li> <li>Create a function to save the data of your simulation runs (e.g., agent’s status, age, etc.)</li> <li>Define a parameter variation experiment.</li> <li>Define a variable to specify where to save the data (i.e., path).</li> <li>Write code in the experiment Java Actions section so that to save data every time you run an experiment.</li> <li>Import functions in the advanced Java section of the experiment.</li> </ul> <h2 id="databases">Databases</h2> <p>I define two tables (<code class="language-plaintext highlighter-rouge">data1</code> and <code class="language-plaintext highlighter-rouge">data2</code>). Each agent saves its data at a given rate. After 5 years, the simulation will finish.</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">insertInto</span><span class="o">(</span><span class="n">data1</span><span class="o">)</span>
    <span class="o">.</span><span class="na">columns</span><span class="o">(</span><span class="n">data1</span><span class="o">.</span><span class="na">iteration</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">replicate</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">id</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">dtime</span><span class="o">,</span> <span class="n">data1</span><span class="o">.</span><span class="na">drandom</span><span class="o">)</span>
    <span class="o">.</span><span class="na">values</span><span class="o">(</span><span class="n">main</span><span class="o">.</span><span class="na">v_iteration</span><span class="o">,</span> <span class="n">main</span><span class="o">.</span><span class="na">v_replicate</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">getIndex</span><span class="o">(),</span> <span class="n">time</span><span class="o">(),</span> <span class="n">normal</span><span class="o">(</span><span class="mf">1.0</span><span class="o">))</span>
    <span class="o">.</span><span class="na">execute</span><span class="o">();</span>

<span class="n">insertInto</span><span class="o">(</span><span class="n">data2</span><span class="o">)</span>
    <span class="o">.</span><span class="na">columns</span><span class="o">(</span><span class="n">data2</span><span class="o">.</span><span class="na">iteration</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">replicate</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">id</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">dtime</span><span class="o">,</span> <span class="n">data2</span><span class="o">.</span><span class="na">drandom</span><span class="o">)</span>
    <span class="o">.</span><span class="na">values</span><span class="o">(</span><span class="n">main</span><span class="o">.</span><span class="na">v_iteration</span><span class="o">,</span> <span class="n">main</span><span class="o">.</span><span class="na">v_replicate</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">getIndex</span><span class="o">(),</span> <span class="n">time</span><span class="o">(),</span> <span class="n">normal</span><span class="o">(</span><span class="mf">0.3</span><span class="o">))</span>
    <span class="o">.</span><span class="na">execute</span><span class="o">();</span>

<span class="k">if</span> <span class="o">(</span><span class="n">time</span><span class="o">()</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">finishSimulation</span><span class="o">();</span>
<span class="o">}</span></code></pre></figure> <p>The tables include a column with the experiment iteration and replicate, in addition to the agent’s index, time, and a random value from a normal distribution.</p> <h2 id="from-db-to-csv">From DB to CSV</h2> <p>The key function to export the data to a CSV file is <code class="language-plaintext highlighter-rouge">f_SQLToCSV</code>. It uses two arguments, a SQL query (<code class="language-plaintext highlighter-rouge">query</code>) and the path to an output file (<code class="language-plaintext highlighter-rouge">filename</code>). For instance, we can write:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">f_SQLToCSV</span><span class="o">(</span><span class="s">"select * from data1"</span><span class="o">,</span> <span class="s">"output/data1"</span><span class="o">)</span></code></pre></figure> <p>You can use any query for your data, giving you a lot of flexibility on what to export to a CSV file. The <code class="language-plaintext highlighter-rouge">f_SQLToCSV</code> method is:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ResultSet</span> <span class="n">rs</span> <span class="o">=</span> <span class="n">selectResultSet</span><span class="o">(</span><span class="n">query</span><span class="o">);</span>
<span class="k">try</span> <span class="o">{</span>
    <span class="nc">File</span> <span class="n">file</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s">".csv"</span><span class="o">);</span>
    <span class="n">file</span><span class="o">.</span><span class="na">getParentFile</span><span class="o">().</span><span class="na">mkdirs</span><span class="o">();</span>
    <span class="nc">FileWriter</span> <span class="n">fw</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FileWriter</span><span class="o">(</span><span class="n">file</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="na">getMetaData</span><span class="o">().</span><span class="na">getColumnCount</span><span class="o">();</span>
    <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">cols</span><span class="o">;</span> <span class="n">i</span> <span class="o">++){</span>
        <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">getMetaData</span><span class="o">().</span><span class="na">getColumnLabel</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="na">toLowerCase</span><span class="o">());</span>
        <span class="k">if</span><span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="o">)</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">';'</span><span class="o">);</span>
        <span class="k">else</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">'\n'</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">next</span><span class="o">())</span> <span class="o">{</span>
        <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">cols</span><span class="o">;</span> <span class="n">i</span> <span class="o">++){</span>
            <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">rs</span><span class="o">.</span><span class="na">getString</span><span class="o">(</span><span class="n">i</span><span class="o">));</span>
            <span class="k">if</span><span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="o">)</span> <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">';'</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">fw</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="sc">'\n'</span><span class="o">);</span>
     <span class="o">}</span>
     <span class="n">fw</span><span class="o">.</span><span class="na">flush</span><span class="o">();</span>
     <span class="n">fw</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">getEngine</span><span class="o">().</span><span class="na">pause</span><span class="o">();</span>
    <span class="n">traceln</span><span class="o">(</span><span class="s">"--&gt; An Exception happened, continue? ..."</span><span class="o">);</span>
    <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
<span class="o">}</span></code></pre></figure> <p>The next step would be to create an experiment and complete the Java actions accordingly. First, we clear our tables.</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// inital experiment setup</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span></code></pre></figure> <p>Then, we collect information on the iteration and replicate of the simulation run:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// before simulation run</span>
<span class="n">root</span><span class="o">.</span><span class="na">v_iteration</span> <span class="o">=</span> <span class="n">getCurrentIteration</span><span class="o">();</span>
<span class="n">root</span><span class="o">.</span><span class="na">v_replicate</span> <span class="o">=</span> <span class="n">getCurrentReplication</span><span class="o">();</span></code></pre></figure> <p>Finally, at the end of the experiment, we save the data and clear the tables again:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// after experiment</span>
<span class="n">f_exportTables</span><span class="o">(</span><span class="n">v_path</span><span class="o">);</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span>
<span class="n">deleteFrom</span><span class="o">(</span><span class="n">data1</span><span class="o">).</span><span class="na">execute</span><span class="o">();</span></code></pre></figure> <p>The method <code class="language-plaintext highlighter-rouge">f_exportTables</code> is just a function that goes through each table and export them to a CSV file. <code class="language-plaintext highlighter-rouge">v_tables</code> is string array with the name of the tables I want to export <code class="language-plaintext highlighter-rouge">{"data1", "data2"}</code>:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">tables</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;();</span>
<span class="k">for</span><span class="o">(</span><span class="nc">String</span> <span class="n">tab</span> <span class="o">:</span> <span class="n">v_tables</span><span class="o">)</span> <span class="o">{</span>
   <span class="n">tables</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">tab</span><span class="o">);</span>
<span class="o">}</span>
<span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">t</span> <span class="o">:</span> <span class="n">tables</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">f_SQLToCSV</span><span class="o">(</span><span class="s">"select * from "</span> <span class="o">+</span> <span class="n">t</span><span class="o">,</span> <span class="n">path</span> <span class="o">+</span> <span class="n">t</span><span class="o">);</span>
<span class="o">}</span></code></pre></figure> <p>Remember to import some functions in the <code class="language-plaintext highlighter-rouge">imports section</code>:</p> <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// imports section</span>
<span class="kn">import</span> <span class="nn">java.io.BufferedWriter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.File</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.FileWriter</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.BufferedReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.FileReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.text.*</span><span class="o">;</span></code></pre></figure> <p>From there, we can create additional functions to select the tables to be exported. For more details, download the <a href="/assets/files/DBToCSV.zip">Anylogic File here</a>.</p> <h2 id="update">Update</h2> <p>When running several replicates of my simulation, saving the information in a database didn’t work as expected. My simulation just crashed, and I was not able to keep the data. I finally decided to follow my previous approach: create many CSV files – one per iteration and replicate – and read them using an R or Python function. I know you end up with a lot of CSV files, but at least the simulation doesn’t crash, and you can recover the output of your simulation as it goes.</p>]]></content><author><name>Sebastian Daza</name></author><category term="anylogic"/><category term="ABM"/><summary type="html"><![CDATA[How to transform a database into CSV using Anylogic]]></summary></entry><entry><title type="html">Oh, descriptive tables (R + Latex)!</title><link href="https://sdaza.com/blog/2020/descriptive-tables/" rel="alternate" type="text/html" title="Oh, descriptive tables (R + Latex)!"/><published>2020-05-12T00:00:00+02:00</published><updated>2020-05-12T00:00:00+02:00</updated><id>https://sdaza.com/blog/2020/descriptive-tables</id><content type="html" xml:base="https://sdaza.com/blog/2020/descriptive-tables/"><![CDATA[<p>It’s been a while since my last post. It’s time to catch up!</p> <p>Every time I write a paper or report, I need to create descriptive tables using Latex. Over and over I create Adhoc tables, and I say to myself: <em>Write a general function so you can save time in the next paper!</em> I know there are some solutions out there, but in general, I feel they are not flexible enough.</p> <p>I introduce a far from perfect function to create descriptive tables in Latex. The steps and structure are quite simple:</p> <ol> <li>Write a function to summarize your data with any stats you want</li> <li>Define a list with the data plus column names (labels)</li> </ol> <p>That’s it. You can see the function <a href="https://gist.github.com/sdaza/c4d1089a501d3567be9fb784b1c5a6ab">here</a>. It has some features might be useful:</p> <ul> <li>It deals automatically with factors (categorical variables)</li> <li>You can use different datasets at the same time</li> <li>You can group columns using a variable (e.g., year)</li> <li>You can add long notes at the bottom of the table</li> <li>You can specify your own descriptive function</li> </ul> <p>Let’s start creating some fake data:</p> <ul> <li>5 variables</li> <li>Variable 3 is a factor (i.e., categorical)</li> <li>Variable 5 is a grouping column</li> </ul> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">14332</span><span class="p">)</span><span class="w">
</span><span class="n">devtools</span><span class="o">::</span><span class="n">source_gist</span><span class="p">(</span><span class="s2">"c4d1089a501d3567be9fb784b1c5a6ab"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create two fake datasets</span><span class="w">
</span><span class="n">n1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="n">dat1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="w">
    </span><span class="n">var1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">n1</span><span class="p">),</span><span class="w">
    </span><span class="n">var2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.8</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
    </span><span class="n">var3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.4</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w">
        </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
        </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Medium"</span><span class="p">,</span><span class="w"> </span><span class="s2">"High"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Very high"</span><span class="p">)),</span><span class="w">
    </span><span class="n">var4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">),</span><span class="w">
    </span><span class="n">var5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">n2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">200</span><span class="w">
</span><span class="n">dat2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="w">
    </span><span class="n">var1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">),</span><span class="w">
    </span><span class="n">var2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
    </span><span class="n">var3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.35</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">),</span><span class="w">
        </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
        </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Very low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Low"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Medium"</span><span class="p">,</span><span class="w"> </span><span class="s2">"High"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Very high"</span><span class="p">)),</span><span class="w">
    </span><span class="n">var4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="m">2000</span><span class="p">,</span><span class="w"> </span><span class="m">300</span><span class="p">),</span><span class="w">
    </span><span class="n">var5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">n2</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">datasets</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"Data 1"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dat1</span><span class="p">,</span><span class="w"> </span><span class="s2">"Data 2"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dat2</span><span class="p">)</span><span class="w">
</span><span class="n">variables</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"var"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"var"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">))</span><span class="w">
</span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Variable "</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Variable "</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Mean"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Median"</span><span class="p">,</span><span class="w"> </span><span class="s2">"SD"</span><span class="p">)</span></code></pre></figure> <p>We can define a descriptive function:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># descriptive function</span><span class="w">
</span><span class="n">myDescriptives</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
    </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">md</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="nf">return</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">md</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="p">))</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create table</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_01.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%; height: 50%;"/> </div> <p>Thus, the grouping of rows is defined by the name of each dataset in the list. We can add a note, just remember to add <code class="language-plaintext highlighter-rouge">\usepackage[flushleft]{threeparttable}</code> to your Latex document:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># table + note</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">note</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"This is a very long long long long long long long long long note."</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_02.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%; height: 50%;"/> </div> <p>We can also slice the descriptives by group:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># group columns</span><span class="w">
</span><span class="n">createDescriptiveTable</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span><span class="w">
    </span><span class="n">summary_function</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myDescriptives</span><span class="p">,</span><span class="w">
    </span><span class="n">column_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w">
    </span><span class="n">variable_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
    </span><span class="n">group_variable</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"var5"</span><span class="p">,</span><span class="w">
    </span><span class="n">arraystretch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w">
    </span><span class="n">tabcolsep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w">
    </span><span class="n">note</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"This is a very long long long long long long long long long note."</span><span class="p">,</span><span class="w">
    </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Descriptive statistics"</span><span class="p">,</span><span class="w">
    </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tab:descriptive"</span><span class="p">,</span><span class="w">
    </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"example_03.tex"</span><span class="p">)</span></code></pre></figure> <div> <img src="/assets/img/table_examples/example_table_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%; height: 90%;"/> </div> <p>It’s just a first version. I will add more features soon.</p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="latexs"/><summary type="html"><![CDATA[How to create latex descriptive tables in R]]></summary></entry><entry><title type="html">Reading CDC mortality files using R</title><link href="https://sdaza.com/blog/2016/read-mortality-data/" rel="alternate" type="text/html" title="Reading CDC mortality files using R"/><published>2016-10-05T00:00:00+02:00</published><updated>2016-10-05T00:00:00+02:00</updated><id>https://sdaza.com/blog/2016/read-mortality-data</id><content type="html" xml:base="https://sdaza.com/blog/2016/read-mortality-data/"><![CDATA[<p>Reading fixed-width text files might be challenging, specially when we don’t have a dictionary file. In this post, I show steps to read CDC files in a more systematic way. In this example, I import a compress mortality file (CMF 1979-1988) available <a href="http://www.cdc.gov/nchs/data_access/cmf.htm">here</a> and whose codebook (or layout) is <a href="http://www.cdc.gov/nchs/data/mortab/filelayout68_88.pdf">here</a>.</p> <p>To read this file, usually with extension <code class="language-plaintext highlighter-rouge">.txt</code> or <code class="language-plaintext highlighter-rouge">.dat</code>, I first need to know where each column starts and finishes. What I get from the pdf file is something like this:</p> <p><img src="/assets/img/mortalityLayout.png" alt=""/></p> <p>The layout is usually a codebook in Word/PDF or just plain text file. Here, I copy the PDF text and put it in a plain text file. I use a text editor (e.g., <a href="https://www.sublimetext.com/">Sublime Text</a>) and <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a> to extract the information I need.</p> <p>I have to select every row with this pattern: <code class="language-plaintext highlighter-rouge">1-2 2 FIPS State code Numeric</code>. That is, a number followed by a hyphen (although not always, particularly when the width of the column is one), spaces, another number, spaces, and then any text. I use the following regular expression to get that pattern: <code class="language-plaintext highlighter-rouge">(^[0-9]+).([0-9]+)\s+([0-9])\s+(.+)</code>. Using the Sublime package <a href="https://packagecontrol.io/packages/Filter%20Lines">Filter Lines</a> I get something like this (you can also just copy the selected lines):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1-2 2 FIPS State code Numeric
3-5 FIPS county code Numeric
6-9 4 Year of death Numeric
11-12 2 Age at death Numeric
13-16 4 ICD code for underlying cause-of-death 3 digits: Numeric
17-19 3 Cause-of-Death Recode Numeric
20-23 4 Number of deaths Numeric
</code></pre></div></div> <p>This approach might be particularly useful when you have a long PDF/Word file and you want to extract most of the variables. You would need to adapt the regular expressions I’m using to the particular patterns of your codebook.</p> <p>To simplify, I format this text as a comma-separated values file (csv). Replacing this regular expression <code class="language-plaintext highlighter-rouge">([0-9]+)(-)([0-9]+)(\s)([0-9]+)(\s)(.+)(\s)(Numeric)</code> by <code class="language-plaintext highlighter-rouge">\1,\3,\5,\7,\9</code> I get:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1,2,2,FIPS State code,Numeric
3,5,3,FIPS county code,Numeric
6,9,4,Year of death,Numeric
11,12,2,Age at death,Numeric
13,16,4,ICD code for underlying cause-of-death 3 digits:,Numeric
17,19,3,Cause-of-Death Recode,Numeric
20,23,4,Number of deaths,Numeric
</code></pre></div></div> <p>Then, I read the layout file:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># define names of columns</span><span class="w">
</span><span class="n">colnames</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"start"</span><span class="p">,</span><span class="w"> </span><span class="s2">"end"</span><span class="p">,</span><span class="w"> </span><span class="s2">"width"</span><span class="p">,</span><span class="w"> </span><span class="s2">"name"</span><span class="p">,</span><span class="w"> </span><span class="s2">"type"</span><span class="p">)</span><span class="w">
</span><span class="n">dict</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"data/dictMortality.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">col.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">colnames</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   start end width                                             name    type
## 1     1   2     2                                  FIPS State code Numeric
## 2     3   5     3                                 FIPS county code Numeric
## 3     6   9     4                                    Year of death Numeric
## 4    11  12     2                                     Age at death Numeric
## 5    13  16     4 ICD code for underlying cause-of-death 3 digits: Numeric
## 6    17  19     3                            Cause-of-Death Recode Numeric
## 7    20  23     4                                 Number of deaths Numeric</code></pre></figure> <p>Now, I can read the fixed-width data file. I use the <a href="https://github.com/hadley/readr">readr</a> package (in my experience relatively fast for big datasets ~ 1 GB).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">readr</span><span class="p">)</span><span class="w">

</span><span class="c1"># create name of variables</span><span class="w">
</span><span class="n">cnames</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"state"</span><span class="p">,</span><span class="w"> </span><span class="s2">"county"</span><span class="p">,</span><span class="w"> </span><span class="s2">"year"</span><span class="p">,</span><span class="w"> </span><span class="s2">"age"</span><span class="p">,</span><span class="w"> </span><span class="s2">"icd"</span><span class="p">,</span><span class="w"> </span><span class="s2">"cause"</span><span class="p">,</span><span class="w"> </span><span class="s2">"deaths"</span><span class="p">)</span><span class="w">

</span><span class="c1"># read mortality file</span><span class="w">
</span><span class="n">mort</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_fwf</span><span class="p">(</span><span class="s2">"data/mort7988.txt"</span><span class="p">,</span><span class="w"> </span><span class="n">fwf_positions</span><span class="p">(</span><span class="n">dict</span><span class="o">$</span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">dict</span><span class="o">$</span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">cnames</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## # A tibble: 8,776,385 x 7
##    state county  year   age   icd cause deaths
##    &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;
##  1    01    001  1979    04  5789   780      1
##  2    01    001  1979    04  7980   770      1
##  3    01    001  1979    08  8121   800      1
##  4    01    001  1979    09  3439   780      1
##  5    01    001  1979    09  8120   800      2
##  6    01    001  1979    09  8189   800      1
##  7    01    001  1979    10  1629   180      1
##  8    01    001  1979    10  2396   250      1
##  9    01    001  1979    10  4289   410      1
## 10    01    001  1979    10  8070   810      1
## # ... with 8,776,375 more rows</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># year distribution</span><span class="w">
</span><span class="n">table</span><span class="p">(</span><span class="n">mort</span><span class="o">$</span><span class="n">year</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   1979   1980   1981   1982   1983   1984   1985   1986   1987   1988
## 831605 854860 854198 850505 867280 875607 894176 905736 912551 929867</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># number of deaths</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">mort</span><span class="o">$</span><span class="n">deaths</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 20398153</code></pre></figure> <p>Hopefully, this might save you some time!</p> <p><strong>Last Update: 06/29/2017</strong></p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="demography"/><summary type="html"><![CDATA[Reading fixed-width text files might be challenging, specially when we don’t have a dictionary file. In this post, I show steps to read CDC files in a more systematic way. In this example, I import a compress mortality file (CMF 1979-1988) available here and whose codebook (or layout) is here.]]></summary></entry><entry><title type="html">R package to compute statistics from the American Community Survey (ACS) and Decennial US Census</title><link href="https://sdaza.com/blog/2016/acsr/" rel="alternate" type="text/html" title="R package to compute statistics from the American Community Survey (ACS) and Decennial US Census"/><published>2016-07-06T00:00:00+02:00</published><updated>2016-07-06T00:00:00+02:00</updated><id>https://sdaza.com/blog/2016/acsr</id><content type="html" xml:base="https://sdaza.com/blog/2016/acsr/"><![CDATA[<p>The <code class="language-plaintext highlighter-rouge">acsr</code> package helps extracting variables and computing statistics using the America Community Survey and Decennial US Census. It was created for the <a href="http://www.apl.wisc.edu/">Applied Population Laboratory</a> (APL) at the University of Wisconsin-Madison.</p> <h2 class="section-heading">Installation</h2> <p>The functions depend on the <code class="language-plaintext highlighter-rouge">acs</code> and <code class="language-plaintext highlighter-rouge">data.table</code> packages, so it is necessary to install then before using <code class="language-plaintext highlighter-rouge">acsr</code>. The <code class="language-plaintext highlighter-rouge">acsr</code> package is hosted on a github repository and can be installed using <code class="language-plaintext highlighter-rouge">devtools</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"sdaza/acsr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">acsr</span><span class="p">)</span></code></pre></figure> <p>Remember to set the ACS API key, to check the help documentation and the default values of the <code class="language-plaintext highlighter-rouge">acsr</code> functions.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">api.key.install</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s2">"*"</span><span class="p">)</span><span class="w">
</span><span class="o">?</span><span class="n">sumacs</span><span class="w">
</span><span class="o">?</span><span class="n">acsdata</span></code></pre></figure> <p>The default dataset is <code class="language-plaintext highlighter-rouge">acs</code>, the level is <code class="language-plaintext highlighter-rouge">state</code> (Wisconsin, <code class="language-plaintext highlighter-rouge">state = "WI"</code>), the <code class="language-plaintext highlighter-rouge">endyear</code> is 2014, and the confidence level to compute margins of error (MOEs) is 90%.</p> <h2 class="section-heading">Levels</h2> <p>The <code class="language-plaintext highlighter-rouge">acsr</code> functions can extract all the levels available in the <code class="language-plaintext highlighter-rouge">acs</code> package. The table below shows the summary and required levels when using the <code class="language-plaintext highlighter-rouge">acsdata</code> and <code class="language-plaintext highlighter-rouge">sumacs</code> functions:</p> <table> <thead> <tr> <th>summary number</th> <th>levels</th> </tr> </thead> <tbody> <tr> <td>010</td> <td>us</td> </tr> <tr> <td>020</td> <td>region</td> </tr> <tr> <td>030</td> <td>division</td> </tr> <tr> <td>040</td> <td>state</td> </tr> <tr> <td>050</td> <td>state, county</td> </tr> <tr> <td>060</td> <td>state, county, county.subdivision</td> </tr> <tr> <td>140</td> <td>state, county, tract</td> </tr> <tr> <td>150</td> <td>state, county, tract, block.group</td> </tr> <tr> <td>160</td> <td>state, place</td> </tr> <tr> <td>250</td> <td>american.indian.area</td> </tr> <tr> <td>320</td> <td>state, msa</td> </tr> <tr> <td>340</td> <td>state, csa</td> </tr> <tr> <td>350</td> <td>necta</td> </tr> <tr> <td>400</td> <td>urban.area</td> </tr> <tr> <td>500</td> <td>state, congressional.district</td> </tr> <tr> <td>610</td> <td>state, state.legislative.district.upper</td> </tr> <tr> <td>620</td> <td>state, state.legislative.district.lower</td> </tr> <tr> <td>795</td> <td>state, puma</td> </tr> <tr> <td>860</td> <td>zip.code</td> </tr> <tr> <td>950</td> <td>state, school.district.elementary</td> </tr> <tr> <td>960</td> <td>state, school.district.secondary</td> </tr> <tr> <td>970</td> <td>state, school.district.unified</td> </tr> </tbody> </table> <h2 class="section-heading">Getting variables and statistics</h2> <p>We can use the <code class="language-plaintext highlighter-rouge">sumacs</code> function to extract variable and statistics. We have to specify the corresponding method (e.g., <em>proportion</em> or just <em>variable</em>), and the name of the statistic or variable to be included in the output.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w"> </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myvar"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">,</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel geoid division mynewvar_est mynewvar_moe myvar_est myvar_moe
## 1:      030    NA        1       0.0762     0.000347    770306      3490
## 2:      030    NA        2       0.1182     0.000278   3332150      9171
## 3:      030    NA        3       0.0599     0.000196   1819417      7209
## 4:      030    NA        4       0.0411     0.000277    547577      4461
## 5:      030    NA        5       0.1108     0.000246   4526480     11869
## 6:      030    NA        6       0.0320     0.000265    402475      3781
## 7:      030    NA        7       0.2203     0.000469   5318126     13044
## 8:      030    NA        8       0.1582     0.000602   2279303     10746
## 9:      030    NA        9       0.2335     0.000501   7765838     20289</code></pre></figure> <p>To download the data can be slow, especially when many levels are being used (e.g., blockgroup). A better approach in those cases is, first, download the data using the function <code class="language-plaintext highlighter-rouge">acsdata</code> , and then use them as input.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">mydata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">acsdata</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 /  b16004_001)"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] ". . . . . .  Getting division data"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w"> </span><span class="s2">"b16004_026"</span><span class="p">),</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myvar"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">,</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"division"</span><span class="p">),</span><span class="w">
        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mydata</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel geoid division mynewvar_est mynewvar_moe myvar_est myvar_moe
## 1:      030    NA        1       0.0762     0.000347    770306      3490
## 2:      030    NA        2       0.1182     0.000278   3332150      9171
## 3:      030    NA        3       0.0599     0.000196   1819417      7209
## 4:      030    NA        4       0.0411     0.000277    547577      4461
## 5:      030    NA        5       0.1108     0.000246   4526480     11869
## 6:      030    NA        6       0.0320     0.000265    402475      3781
## 7:      030    NA        7       0.2203     0.000469   5318126     13044
## 8:      030    NA        8       0.1582     0.000602   2279303     10746
## 9:      030    NA        9       0.2335     0.000501   7765838     20289</code></pre></figure> <h2 class="section-heading">Standard errors</h2> <p>When computing statistics there are two ways to define the standard errors:</p> <ul> <li>Including all standard errors of the variables used to compute a statistic (<code class="language-plaintext highlighter-rouge">one.zero = FALSE</code>)</li> <li>Include all standard errors except those of variables that are equal to zero. Only the maximum standard error of the variables equal to zero is included (<code class="language-plaintext highlighter-rouge">one.zero = TRUE</code>)</li> <li>The default value is <code class="language-plaintext highlighter-rouge">one.zero = TRUE</code></li> </ul> <p>For more details about how standard errors are computed for proportions, ratios and aggregations look at <a href="https://www.census.gov/content/dam/Census/library/publications/2008/acs/ACSGeneralHandbook.pdf">A Compass for Understanding and Using American Community Survey Data</a>.</p> <p>Below an example when estimating proportions and using <code class="language-plaintext highlighter-rouge">one.zero = FALSE</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048) / b16004_001"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tract"</span><span class="p">,</span><span class="w">
            </span><span class="n">county</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">
            </span><span class="n">tract</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">950501</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2013</span><span class="p">,</span><span class="w">
            </span><span class="n">one.zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2013"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel       geoid st_fips cnty_fips tract_fips mynewvar_est mynewvar_moe
## 1:      140 55001950501      55         1     950501       0.0226       0.0252</code></pre></figure> \[SE = \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2 + 5.47 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0252\] <p>When <code class="language-plaintext highlighter-rouge">one.zero = TRUE</code>:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048) / b16004_001"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"tract"</span><span class="p">,</span><span class="w">
            </span><span class="n">county</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">
            </span><span class="n">tract</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">950501</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2013</span><span class="p">,</span><span class="w">
            </span><span class="n">one.zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2013"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    sumlevel       geoid st_fips cnty_fips tract_fips mynewvar_est mynewvar_moe
## 1:      140 55001950501      55         1     950501       0.0226       0.0245</code></pre></figure> \[SE_{\text{ one.zero}} \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0245\] <p>When the square root value in the standard error formula doesn’t exist (e.g., the square root of a negative number), the ratio formula is instead used. The ratio adjustment is done <strong>variable by variable</strong> .</p> <p>It can also be that the <code class="language-plaintext highlighter-rouge">one.zero</code> option makes the square root undefinable. In those cases, the function uses again the <strong>ratio</strong> formula to compute standard errors. There is also a possibility that the standard error estimates using the <strong>ratio</strong> formula are higher than the <strong>proportion</strong> estimates without the <code class="language-plaintext highlighter-rouge">one.zero</code> option.</p> <h2 class="section-heading">Decennial Data from the US Census</h2> <p>Let’s get the African American and Hispanic population by state. In this case, we don’t have any estimation of margin of error.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"p0080004"</span><span class="p">,</span><span class="w"> </span><span class="s2">"p0090002"</span><span class="p">),</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"variable"</span><span class="p">,</span><span class="w">
            </span><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"sf1"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"state"</span><span class="p">,</span><span class="w">
            </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"*"</span><span class="p">,</span><span class="w">
            </span><span class="n">endyear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2010</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: sf1 2010"
## [1] ". . . . . .  ACS/Census variables : 2"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Getting state data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     sumlevel geoid st_fips p0080004 p0090002
##  1:      040    01      01  1251311   185602
##  2:      040    02      02    23263    39249
##  3:      040    04      04   259008  1895149
##  4:      040    05      05   449895   186050
##  5:      040    06      06  2299072 14013719
##  6:      040    08      08   201737  1038687
##  7:      040    09      09   362296   479087
##  8:      040    10      10   191814    73221
##  9:      040    11      11   305125    54749
## 10:      040    12      12  2999862  4223806
## 11:      040    13      13  2950435   853689
## 12:      040    15      15    21424   120842
## 13:      040    16      16     9810   175901
## 14:      040    17      17  1866414  2027578
## 15:      040    18      18   591397   389707
## 16:      040    19      19    89148   151544
## 17:      040    20      20   167864   300042
## 18:      040    21      21   337520   132836
## 19:      040    22      22  1452396   192560
## 20:      040    23      23    15707    16935
## 21:      040    24      24  1700298   470632
## 22:      040    25      25   434398   627654
## 23:      040    26      26  1400362   436358
## 24:      040    27      27   274412   250258
## 25:      040    28      28  1098385    81481
## 26:      040    29      29   693391   212470
## 27:      040    30      30     4027    28565
## 28:      040    31      31    82885   167405
## 29:      040    32      32   218626   716501
## 30:      040    33      33    15035    36704
## 31:      040    34      34  1204826  1555144
## 32:      040    35      35    42550   953403
## 33:      040    36      36  3073800  3416922
## 34:      040    37      37  2048628   800120
## 35:      040    38      38     7960    13467
## 36:      040    39      39  1407681   354674
## 37:      040    40      40   277644   332007
## 38:      040    41      41    69206   450062
## 39:      040    42      42  1377689   719660
## 40:      040    44      44    60189   130655
## 41:      040    45      45  1290684   235682
## 42:      040    46      46    10207    22119
## 43:      040    47      47  1057315   290059
## 44:      040    48      48  2979598  9460921
## 45:      040    49      49    29287   358340
## 46:      040    50      50     6277     9208
## 47:      040    51      51  1551399   631825
## 48:      040    53      53   240042   755790
## 49:      040    54      54    63124    22268
## 50:      040    55      55   359148   336056
## 51:      040    56      56     4748    50231
## 52:      040    72      72   461498  3688455
##     sumlevel geoid st_fips p0080004 p0090002</code></pre></figure> <h2 class="section-heading">Output</h2> <p>The output can be formatted using a wide or long format:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"division"</span><span class="p">,</span><span class="w">
            </span><span class="n">format.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"long"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    geoid sumlevel division var_name    est      moe
## 1:    NA      030        1 mynewvar 0.0762 0.000347
## 2:    NA      030        2 mynewvar 0.1182 0.000278
## 3:    NA      030        3 mynewvar 0.0599 0.000196
## 4:    NA      030        4 mynewvar 0.0411 0.000277
## 5:    NA      030        5 mynewvar 0.1108 0.000246
## 6:    NA      030        6 mynewvar 0.0320 0.000265
## 7:    NA      030        7 mynewvar 0.2203 0.000469
## 8:    NA      030        8 mynewvar 0.1582 0.000602
## 9:    NA      030        9 mynewvar 0.2335 0.000501</code></pre></figure> <p>And it can also be exported to a csv file:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
            </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
            </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
            </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"division"</span><span class="p">,</span><span class="w">
            </span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"myfile.out"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] "Data exported to a CSV file! "</code></pre></figure> <h2 class="section-heading">Combining geographic levels</h2> <p>We can combine geographic levels using two methods: (1) <code class="language-plaintext highlighter-rouge">sumacs</code> and (2) <code class="language-plaintext highlighter-rouge">combine.output</code>. The first one allows only single combinations, the second multiple ones.</p> <p>If I want to combine two states (e.g., Wisconsin and Minnesota) I can use:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">sumacs</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
    </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
    </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"state"</span><span class="p">,</span><span class="w">
    </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"WI"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MN"</span><span class="p">),</span><span class="w">
    </span><span class="n">combine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
    </span><span class="n">print.levels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    geoid combined_group mynewvar_est mynewvar_moe
## 1:    NA      aggregate        0.042     0.000331</code></pre></figure> <p>If I want to put together multiple combinations (e.g., groups of states):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">combine.output</span><span class="p">(</span><span class="s2">"(b16004_004 + b16004_026 + b16004_048 / b16004_001)"</span><span class="p">,</span><span class="w">
    </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mynewvar"</span><span class="p">,</span><span class="w">
    </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"prop"</span><span class="p">,</span><span class="w">
    </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"state"</span><span class="p">,</span><span class="w"> </span><span class="s2">"state"</span><span class="p">),</span><span class="w">
    </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"WI"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MN"</span><span class="p">),</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s2">"CA"</span><span class="p">,</span><span class="w"> </span><span class="s2">"OR"</span><span class="p">)),</span><span class="w"> </span><span class="c1"># nested list</span><span class="w">
    </span><span class="n">combine.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WI+MN"</span><span class="p">,</span><span class="w"> </span><span class="s2">"CA+OR"</span><span class="p">),</span><span class="w">
    </span><span class="n">print.levels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] ". . . . . .  Defining WI+MN"
## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Defining CA+OR"
## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting combined data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    combined_group mynewvar_est mynewvar_moe
## 1:          WI+MN        0.042     0.000331
## 2:          CA+OR        0.269     0.000565</code></pre></figure> <h2 class="section-heading">A map?</h2> <p>Let’s color a map using poverty by county:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">pov</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sumacs</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"b17001_002 / b17001_001 * 100"</span><span class="p">,</span><span class="w">
        </span><span class="n">varname</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"pov"</span><span class="p">),</span><span class="w">
        </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"prop"</span><span class="p">),</span><span class="w">
        </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"county"</span><span class="p">),</span><span class="w">
        </span><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"*"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "Extracting data from: acs 2014"
## [1] ". . . . . .  ACS/Census variables : 2"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting county data"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">choroplethr</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">choroplethrMaps</span><span class="p">)</span><span class="w">
</span><span class="n">pov</span><span class="p">[,</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">geoid</span><span class="p">)]</span><span class="w">
</span><span class="n">setnames</span><span class="p">(</span><span class="n">pov</span><span class="p">,</span><span class="w"> </span><span class="s2">"pov_est"</span><span class="p">,</span><span class="w"> </span><span class="s2">"value"</span><span class="p">)</span><span class="w">
</span><span class="n">county_choropleth</span><span class="p">(</span><span class="n">pov</span><span class="p">,</span><span class="w"> </span><span class="n">num_colors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2016-07-06-acsr/unnamed-chunk-15-1.png" alt="center"/></p> <p>In sum, the <code class="language-plaintext highlighter-rouge">acsr</code> package:</p> <ul> <li>Reads formulas directly and extracts any ACS/Census variable</li> <li>Provides an automatized and tailored way to obtain indicators and MOEs</li> <li>Allows different outputs’ formats (wide and long, csv)</li> <li>Provides an easy way to adjust MOEs to different confidence levels</li> <li>Includes a variable-by-variable ratio adjustment of standard errors</li> <li>Includes the zero-option when computing standard errors for proportions, ratios, and aggregations</li> <li>Combines geographic levels flexibly</li> </ul> <p><strong>Last Update: 02/07/2016</strong></p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="demography"/><category term="data science"/><summary type="html"><![CDATA[The acsr package helps extracting variables and computing statistics using the America Community Survey and Decennial US Census. It was created for the Applied Population Laboratory (APL) at the University of Wisconsin-Madison.]]></summary></entry><entry><title type="html">Imputing scales using parcels of items as auxiliary variables</title><link href="https://sdaza.com/blog/2015/imputation-parcels/" rel="alternate" type="text/html" title="Imputing scales using parcels of items as auxiliary variables"/><published>2015-10-14T00:00:00+02:00</published><updated>2015-10-14T00:00:00+02:00</updated><id>https://sdaza.com/blog/2015/imputation-parcels</id><content type="html" xml:base="https://sdaza.com/blog/2015/imputation-parcels/"><![CDATA[<p>Multiple imputation of scales generated by several items can be challenging. Fortunately, to impute every single item is not the only solution to the missing data problem. Some practical and <em>theoretically</em> attractive alternative have already been proposed. In this post, I show a simple implementation of what Enders (2010) calls <strong>duplicated-scale imputation</strong>, a method orginally suggested by Eekhout et al. (2011). By the way, thanks <a href="http://www.iriseekhout.com">Iris Eekhout</a> for replying my e-mails!</p> <h2 id="procedure">Procedure</h2> <p>For each scale, I define a number or proportion of items (let’s say <strong>p</strong>) to create parcels (i.e., average of items although not the whole scale). These parcels are, then, used as auxiliary variables to <em>impute</em> the original scales. There are different ways to define parcels. I implemented a solution in my R package <a href="http://github.com/sdaza/sdazar">sdazar</a>, see the function <code class="language-plaintext highlighter-rouge">rowscore</code> for more details.</p> <p>The function <code class="language-plaintext highlighter-rouge">rowscore</code> selects <strong>p</strong> items with the least missing data. For each case (row), it computes the parcels using the available information of the selected items. If only one item has information, only that one will be used. If there are more than one item with valid data, it will average all the selected items. If there are no items available in my initial selection, it picks <strong>p</strong> items from the rest of unselected items to impute the original scale. In this particular example, I create parcels using half of the items:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">rowscore</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">items</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"parcel"</span><span class="p">)</span></code></pre></figure> <p>The reason for using a proportion of the original items is to include as much information as possible, but preventing strong linear dependencies between variables. Ideally, parcels are complete (no missing values). However, in some cases all the items are missing, so parcels can still have missing records (although less than the original scales).</p> <p><strong>Why not just to use the average of the available items?</strong> That solution would implicitly assume that items perfectly correlate with the scale. We know that’s not a good assumption. That is why we worry about creating scales in the first place, right? Using parcels takes advantage of the available information (items with complete information) and the relationship between a portion of items and the scale.</p> <p>Here I show a simple example using the <a href="http://www.cpc.unc.edu/projects/addhealth">National Longitudinal Study of Adolescent to Adult Health (Add Health)</a>. First, let’s look some descriptives of the variables included in the imputation. I am using information from Wave 1 and 2. The scales/scores I am imputing are depression (19 items) and GPA (4 items). Variables ending with <code class="language-plaintext highlighter-rouge">.p</code> are parcels with 1/2 of the items of the original scale.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="nf">dim</span><span class="p">(</span><span class="n">dats</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 12976    14</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">str</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">])</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## Classes 'data.table' and 'data.frame':	12976 obs. of  14 variables:
##  $ female   : Factor w/ 2 levels "0","1": 1 1 1 2 1 1 1 1 1 1 ...
##  $ age      : int  16 16 14 13 14 17 14 17 17 14 ...
##  $ race     : Factor w/ 5 levels "white","black",..: 2 1 1 1 2 1 3 3 3 2 ...
##  $ publicass: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 NA ...
##  $ bmi      : num  27.4 16.3 22.2 18.2 21.9 ...
##  $ gpa1     : num  2 3.25 3.75 3.25 2.25 1 NA 2.25 NA 2.5 ...
##  $ gpa2     : num  2.5 2.5 4 3.75 1.75 1.5 NA 3 1 4 ...
##  $ gpa1.p   : num  2.5 3.5 3.5 3 2.5 1 3.5 3 1 3.5 ...
##  $ gpa2.p   : num  2.5 2.5 4 3.5 1.5 2 1.5 3 1 4 ...
##  $ dep1.p   : num  0.2 0.7 0 0.3 0.4 0.4 0.1 1 0.6 1.2 ...
##  $ dep1     : num  0.263 0.789 0 0.211 0.474 ...
##  $ dep2.p   : num  0.6 0.6 0.1 0.3 0.4 0.6 0.2 1.1 0.8 0.5 ...
##  $ dep2     : num  0.6316 0.5263 0.0526 0.1579 0.3684 ...
##  $ ppvt     : int  101 75 121 96 79 97 103 89 82 120 ...
##  - attr(*, ".internal.selfref")=&lt;externalptr&gt;</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># create summary table using package tables</span><span class="w">
</span><span class="n">missing</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="nf">sum</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">x</span><span class="p">))}</span><span class="w">
</span><span class="n">tabular</span><span class="p">(</span><span class="w">
  </span><span class="p">(</span><span class="w"> </span><span class="n">dep2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2.p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1.p</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2.p</span><span class="w"> </span><span class="o">+</span><span class="w">
    </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa1.p</span><span class="w">  </span><span class="o">+</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bmi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ppvt</span><span class="w"> </span><span class="p">)</span><span class="w">
   </span><span class="o">~</span><span class="w">  </span><span class="p">(</span><span class="n">Format</span><span class="p">(</span><span class="n">digit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Mean"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Mean</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"SD"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Sd</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Min"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Min</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Max"</span><span class="p">)</span><span class="w">
   	</span><span class="o">*</span><span class="w"> </span><span class="n">sdazar</span><span class="o">::</span><span class="n">Max</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">Heading</span><span class="p">(</span><span class="s2">"Missing"</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">missing</span><span class="w"> </span><span class="p">))),</span><span class="w">
  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dats</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##
##         Mean    SD      Min     Max     Missing
##  dep2      0.58    0.39    0.00    2.95   68.00
##  dep2.p    0.58    0.43    0.00    3.00    6.00
##  dep1      0.58    0.39    0.00    2.84   81.00
##  dep1.p    0.62    0.44    0.00    3.00   18.00
##  gpa2      2.86    0.74    1.00    4.00 4710.00
##  gpa2.p    2.76    0.84    1.00    4.00 1238.00
##  gpa1      2.82    0.76    1.00    4.00 2788.00
##  gpa1.p    2.74    0.85    1.00    4.00  342.00
##  age      15.28    1.61   11.00   21.00    9.00
##  bmi      22.37    4.42   11.47   63.47  353.00
##  ppvt    100.17   15.00   13.00  146.00  568.00</code></pre></figure> <p>As expected, the correlation between the scales and parcels is high. GPA has most of the problems. Note that parcels <code class="language-plaintext highlighter-rouge">.p</code> still have missing records, although much less than the original scales.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">dep1</span><span class="p">,</span><span class="w"> </span><span class="n">dep1.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         dep1 dep1.p
## dep1   1.000  0.947
## dep1.p 0.947  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">dep2</span><span class="p">,</span><span class="w"> </span><span class="n">dep2.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         dep2 dep2.p
## dep2   1.000  0.948
## dep2.p 0.948  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">gpa1</span><span class="p">,</span><span class="w"> </span><span class="n">gpa1.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         gpa1 gpa1.p
## gpa1   1.000  0.888
## gpa1.p 0.888  1.000</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">cor</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">gpa2</span><span class="p">,</span><span class="w"> </span><span class="n">gpa2.p</span><span class="p">)],</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         gpa2 gpa2.p
## gpa2   1.000  0.885
## gpa2.p 0.885  1.000</code></pre></figure> <p>Let’s now impute the scales/scores using the R package <em>MICE</em>.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ini</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mice</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">],</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">

</span><span class="c1"># get methods</span><span class="w">
</span><span class="p">(</span><span class="n">meth</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ini</span><span class="o">$</span><span class="n">meth</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    female       age      race publicass       bmi      gpa1      gpa2    gpa1.p    gpa2.p    dep1.p      dep1    dep2.p      dep2      ppvt
##        ""     "pmm"        ""  "logreg"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"     "pmm"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># get predictor matrix</span><span class="w">
</span><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ini</span><span class="o">$</span><span class="n">pred</span></code></pre></figure> <p>I adjust the predictor matrix to avoid feedbacks during the imputation (circularity between variables). The trick is to use only complete variables when imputing <em>parcels</em>.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># predict parcels only with complete variables to avoid feedbacks</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2.p"</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">

</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2.p"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"female"</span><span class="p">,</span><span class="w"> </span><span class="s2">"race"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">

</span><span class="c1"># predict scales using parcels</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"gpa1.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"gpa2.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"dep1.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="n">pred</span><span class="p">[,</span><span class="w"> </span><span class="s2">"dep2.p"</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">

</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa1"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa1.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"gpa2"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa2.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep1"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"dep1.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="n">pred</span><span class="p">[</span><span class="s2">"dep2"</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"dep2.p"</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span></code></pre></figure> <p>Here the adjusted predictor matrix:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">##           female age race publicass bmi gpa1 gpa2 gpa1.p gpa2.p dep1.p dep1 dep2.p dep2 ppvt
## female         0   0    0         0   0    0    0      0      0      0    0      0    0    0
## age            1   0    1         1   1    1    1      0      0      0    1      0    1    1
## race           0   0    0         0   0    0    0      0      0      0    0      0    0    0
## publicass      1   1    1         0   1    1    1      0      0      0    1      0    1    1
## bmi            1   1    1         1   0    1    1      0      0      0    1      0    1    1
## gpa1           1   1    1         1   1    0    1      1      0      0    1      0    1    1
## gpa2           1   1    1         1   1    1    0      0      1      0    1      0    1    1
## gpa1.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## gpa2.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep1.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep1           1   1    1         1   1    1    1      0      0      1    0      0    1    1
## dep2.p         1   0    1         0   0    0    0      0      0      0    0      0    0    0
## dep2           1   1    1         1   1    1    1      0      0      0    1      1    0    1
## ppvt           1   1    1         1   1    1    1      0      0      0    1      0    1    0</code></pre></figure> <p>Let’s impute the data!</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">imp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mice</span><span class="p">(</span><span class="n">dats</span><span class="p">[,</span><span class="w"> </span><span class="n">nvars</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">],</span><span class="w"> </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span></code></pre></figure> <p>Below some plots to explore how the imputation goes.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">plot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"gpa1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"gpa2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"dep1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"dep2"</span><span class="p">))</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-12-1.png" alt="center"/><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-12-2.png" alt="center"/></p> <p>I don’t see any problematic pattern. It seems I get a proper solution. The distribution of the variables also looks right.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">densityplot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-13-1.png" alt="center"/></p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">bwplot</span><span class="p">(</span><span class="n">imp</span><span class="p">,</span><span class="w"> </span><span class="n">gpa1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpa2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">dep2</span><span class="w">  </span><span class="o">~</span><span class="w"> </span><span class="n">.imp</span><span class="p">)</span></code></pre></figure> <p><img src="/assets/img/2015-10-14-imputation_parcels/unnamed-chunk-13-2.png" alt="center"/></p> <p><strong>Last Update: 06/02/2017</strong></p> <hr/> <h3 id="references">References</h3> <p>Enders, Craig K. 2010. <em>Applied Missing Data Analysis</em>. The Guilford Press.</p> <p>Eekhout, Iris, Craig K. Enders, Jos W. R. Twisk, Michiel R. de Boer, Henrica C. W. de Vet, and Martijn W. Heymans. 2015. “Analyzing Incomplete Item Scores in Longitudinal Data by Including Item Score Information as Auxiliary Variables.” <em>Structural Equation Modeling: A Multidisciplinary Journal</em> 22 (4):588-602.</p>]]></content><author><name>Sebastian Daza</name></author><category term="data science"/><category term="R"/><summary type="html"><![CDATA[Multiple imputation of scales generated by several items can be challenging. Fortunately, to impute every single item is not the only solution to the missing data problem. Some practical and theoretically attractive alternative have already been proposed. In this post, I show a simple implementation of what Enders (2010) calls duplicated-scale imputation, a method orginally suggested by Eekhout et al. (2011). By the way, thanks Iris Eekhout for replying my e-mails!]]></summary></entry><entry><title type="html">Simple R package to define sample sizes and MOEs</title><link href="https://sdaza.com/blog/2015/sampler/" rel="alternate" type="text/html" title="Simple R package to define sample sizes and MOEs"/><published>2015-09-30T00:00:00+02:00</published><updated>2015-09-30T00:00:00+02:00</updated><id>https://sdaza.com/blog/2015/sampler</id><content type="html" xml:base="https://sdaza.com/blog/2015/sampler/"><![CDATA[<p>I present a simple R package called <a href="https://github.com/sdaza/sampler"><strong>sampler</strong></a>. The package defines <strong>sample sizes</strong> and <strong>margins of error (MOE)</strong> for proportions, as usually it is needed when designing public opinion surveys. <a href="/survey/2014/01/19/samplesize/">In a previous post</a>, I showed some functions that do mostly the same thing. This new package, though, includes some new features that can be useful when allocating a sample.</p> <h2 id="installation">Installation</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># you have to install devtools first</span><span class="w">
</span><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"sdaza/sampler"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span></code></pre></figure> <h2 id="functions">Functions</h2> <p>The packages contains four functions:</p> <ul> <li><strong>ssize</strong>: computes sample size.</li> <li><strong>serr</strong>: computes MOE.</li> <li><strong>astrata</strong>: assigns sample sizes to strata.</li> <li><strong>serrst</strong>: computes MOE for stratified samples.</li> </ul> <h2 id="define-sample-size-ssize">Define sample size: <em>ssize</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 384</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># design effect (deff) and response rate (rr)</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 512</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># finite population correction</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 370</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># warning message</span><span class="w">
</span><span class="n">ssize</span><span class="p">(</span><span class="m">.05</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## n is bigger than N in some rows: n = N</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 100</code></pre></figure> <h2 id="define-sampling-error-serr">Define sampling error: <em>serr</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">384</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">512</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">370</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.05</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># we still get an answer</span><span class="w">
</span><span class="n">serr</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.90</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0569</code></pre></figure> <h2 id="strata-allocation-astrata">Strata allocation: <em>astrata</em></h2> <p>These examples show how to allocate a sample size into strata. Look at <em>?astrata</em> in <strong>R</strong> for definitions of the allocation procedures that are available.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># I will use data.table</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span><span class="w">
</span><span class="n">chile</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="n">chile</span><span class="p">)</span><span class="w">
</span><span class="n">chile</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr
##  1:   1  328782 0.3
##  2:   2  613328 0.4
##  3:   3  308247 0.5
##  4:   4  759228 0.5
##  5:   5 1808300 0.5
##  6:   6  910577 0.6
##  7:   7 1035593 0.3
##  8:   8 2100494 0.1
##  9:   9  983499 0.2
## 10:  10  834714 0.5
## 11:  11  107334 0.5
## 12:  12  163748 0.4
## 13:  13 7228581 0.6
## 14:  14  401548 0.2
## 15:  15  235081 0.3</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># proportional for a sample of 1000</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aprop</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># fixed (same number by stratum)</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">afixed</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># 40% proportional, 60% fixed</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">a40</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="m">.4</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># 60% proportional, 40% fixed</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">a60</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">wp</span><span class="w"> </span><span class="o">=</span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># square-root</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aroot</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"root"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">)]</span><span class="w">

</span><span class="c1"># neyman</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aneyman</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"neyman"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># standard deviation</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">astdev</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"stdev"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># error</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">aerr</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.11</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"error"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr aprop afixed a40 a60 aroot aneyman astdev aerr
##  1:   1  328782 0.3    18     67  47  38    41      18     66   67
##  2:   2  613328 0.4    34     67  54  47    56      37     71   76
##  3:   3  308247 0.5    17     67  47  37    40      19     72   79
##  4:   4  759228 0.5    43     67  57  53    62      46     72   79
##  5:   5 1808300 0.5   101     67  81  87    96     110     72   79
##  6:   6  910577 0.6    51     67  61  57    68      54     71   76
##  7:   7 1035593 0.3    58     67  63  62    73      58     66   67
##  8:   8 2100494 0.1   118     67  87  98   104      77     43   29
##  9:   9  983499 0.2    55     67  62  60    71      48     58   51
## 10:  10  834714 0.5    47     67  59  55    65      51     72   79
## 11:  11  107334 0.5     6     67  43  30    23       7     72   79
## 12:  12  163748 0.4     9     67  44  32    29      10     71   76
## 13:  13 7228581 0.6   406     67 203 270   192     432     71   76
## 14:  14  401548 0.2    23     67  49  41    45      20     58   51
## 15:  15  235081 0.3    13     67  45  35    35      13     66   67</code></pre></figure> <h2 id="getting-sampling-error-from-a-stratified-sample-serrst">Getting sampling error from a stratified sample: <em>serrst</em></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the second most efficient allocation</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aprop</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0288</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the worst solution</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">afixed</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0518</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">a40</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0339</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0311</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aroot</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0339</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># the most efficient allocation</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aneyman</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0285</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">astdev</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0508</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">aerr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0498</code></pre></figure> <h2 id="combining-criteria">Combining criteria</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># get error for 60% proportional / 40% fixed allocation for each strata</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">error_a60</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># assign sample sizes assuming 13% error for each strata</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">serr13</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">astrata</span><span class="p">(</span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.13</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"error"</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># total error, not that good!</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">serr13</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0586</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">.</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span><span class="w"> </span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">pr</span><span class="p">,</span><span class="w"> </span><span class="n">a60</span><span class="p">,</span><span class="w"> </span><span class="n">error_a60</span><span class="p">,</span><span class="w"> </span><span class="n">serr13</span><span class="p">)]</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr a60 error_a60 serr13
##  1:   1  328782 0.3  38    0.1457     48
##  2:   2  613328 0.4  47    0.1401     55
##  3:   3  308247 0.5  37    0.1611     57
##  4:   4  759228 0.5  53    0.1346     57
##  5:   5 1808300 0.5  87    0.1051     57
##  6:   6  910577 0.6  57    0.1272     55
##  7:   7 1035593 0.3  62    0.1141     48
##  8:   8 2100494 0.1  98    0.0594     20
##  9:   9  983499 0.2  60    0.1012     36
## 10:  10  834714 0.5  55    0.1321     57
## 11:  11  107334 0.5  30    0.1789     57
## 12:  12  163748 0.4  32    0.1697     55
## 13:  13 7228581 0.6 270    0.0584     55
## 14:  14  401548 0.2  41    0.1224     36
## 15:  15  235081 0.3  35    0.1518     48</code></pre></figure> <p>We can adjust a bit more:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># when error is higher than .13, use serr13</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">sfinal</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">error_a60</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">.13</span><span class="p">,</span><span class="w"> </span><span class="n">serr13</span><span class="p">,</span><span class="w"> </span><span class="n">a60</span><span class="p">)]</span><span class="w">

</span><span class="c1"># new error by stratum</span><span class="w">
</span><span class="n">chile</span><span class="p">[,</span><span class="w"> </span><span class="n">error_sfinal</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">sfinal</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pr</span><span class="p">)]</span><span class="w">

</span><span class="c1"># total error, much better!</span><span class="w">
</span><span class="n">serrst</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">sfinal</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pob</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chile</span><span class="o">$</span><span class="n">pr</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0309</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># although the total sample size is now bigger</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">chile</span><span class="o">$</span><span class="n">sfinal</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1109</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##     reg     pob  pr sfinal error_sfinal
##  1:   1  328782 0.3     48       0.1296
##  2:   2  613328 0.4     55       0.1295
##  3:   3  308247 0.5     57       0.1298
##  4:   4  759228 0.5     57       0.1298
##  5:   5 1808300 0.5     87       0.1051
##  6:   6  910577 0.6     57       0.1272
##  7:   7 1035593 0.3     62       0.1141
##  8:   8 2100494 0.1     98       0.0594
##  9:   9  983499 0.2     60       0.1012
## 10:  10  834714 0.5     57       0.1298
## 11:  11  107334 0.5     57       0.1298
## 12:  12  163748 0.4     55       0.1295
## 13:  13 7228581 0.6    270       0.0584
## 14:  14  401548 0.2     41       0.1224
## 15:  15  235081 0.3     48       0.1296</code></pre></figure> <p>That’s it. A simple package to do simple calculations.</p>]]></content><author><name>Sebastian Daza</name></author><category term="survey"/><category term="R"/><summary type="html"><![CDATA[I present a simple R package called sampler. The package defines sample sizes and margins of error (MOE) for proportions, as usually it is needed when designing public opinion surveys. In a previous post, I showed some functions that do mostly the same thing. This new package, though, includes some new features that can be useful when allocating a sample.]]></summary></entry><entry><title type="html">Functions for sample size and error</title><link href="https://sdaza.com/blog/2014/samplesize/" rel="alternate" type="text/html" title="Functions for sample size and error"/><published>2014-01-19T00:00:00+01:00</published><updated>2014-01-19T00:00:00+01:00</updated><id>https://sdaza.com/blog/2014/samplesize</id><content type="html" xml:base="https://sdaza.com/blog/2014/samplesize/"><![CDATA[<p>Here I show two functions in R to define sample sizes and errors of a proportion, taking into account design effect, response rate, finite population correction, and stratification. They are useful when one needs to do these calculations quickly.</p> <p><strong>Note: I created a package with similar functions. <a href="/survey/2015/09/30/sampler/">See here</a>.</strong></p> <p>The inputs are:</p> <ul> <li><strong>n</strong> = sample size</li> <li><strong>e</strong> = sampling error</li> <li><strong>deff</strong> = design effect, by default 1 (SRS)</li> <li><strong>rr</strong> = response rate, by default 1</li> <li><strong>N</strong> = population size, by default NULL (infinite population)</li> <li><strong>cl</strong> = confidence level , by default .95</li> <li><strong>p</strong> = proportion, by default 0.5 (maximum variance of a proportion)</li> <li><strong>relative</strong> = to estimate relative error, by default FALSE</li> </ul> <h2 id="first-load-the-functions">first, load the functions</h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">devtools</span><span class="p">);</span><span class="w"> </span><span class="n">source_gist</span><span class="p">(</span><span class="s2">"7896840"</span><span class="p">)</span></code></pre></figure> <h2 id="serr-sampling-error">serr: sampling error</h2> <p>An example for n = 400 and all inputs at their default values:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="m">400</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.049</code></pre></figure> <p>The output is rounded to 4 decimals. A more complete example:</p> <ul> <li><strong>n</strong> = 400</li> <li><strong>deff</strong> = 1.5</li> <li><strong>response rate</strong> = 80%</li> <li><strong>population size</strong> = 1000</li> </ul> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">400</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.0595</code></pre></figure> <p>The sample size (n) has always to be lower than the population (N). It is important to note that the final sample size used to compute the sampling error is:</p> \[n = \frac{N}{deff} * rr\] <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="m">400</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">350</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## Error: n is bigger than N</code></pre></figure> <h2 id="ssize-sample-size">ssize: sample size</h2> <p>Let’s get a sample size with an error of .03, a population of 1000 elements, a response rate of 0.80, and an effect design of 1.2:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.03</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 775</code></pre></figure> <p>If the the sample size is bigger than the population because of low response rates or big design effects, the sample size will be fixed to N:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.03</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## n is bigger than N in some rows: n = N</code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1000</code></pre></figure> <h2 id="working-with-strata">Working with strata</h2> <p>Finally, we can estimate different sample sizes by strata using vectors or a data frame:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># example sampling frame (4 strata)</span><span class="w">
</span><span class="n">frame</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
	</span><span class="n">strata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w">
	</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="m">5000</span><span class="p">,</span><span class="w"> </span><span class="m">2000</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">),</span><span class="w">
	</span><span class="n">deff</span><span class="w"> </span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="m">.8</span><span class="p">),</span><span class="w">
	</span><span class="n">rr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="m">.9</span><span class="p">,</span><span class="w"> </span><span class="m">.85</span><span class="p">,</span><span class="m">.8</span><span class="p">),</span><span class="w">
	</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">.3</span><span class="p">,</span><span class="w"> </span><span class="m">.6</span><span class="p">,</span><span class="w"> </span><span class="m">.1</span><span class="p">,</span><span class="w"> </span><span class="m">.2</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   strata     N deff   rr   p
## 1      1 10000  1.1 0.80 0.3
## 2      2  5000  1.0 0.90 0.6
## 3      3  2000  1.3 0.85 0.1
## 4      4  1000  0.8 0.80 0.2</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">frame</span><span class="o">$</span><span class="n">n1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ssize</span><span class="p">(</span><span class="n">e</span><span class="o">=</span><span class="m">.02</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">deff</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">rr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">p</span><span class="p">)</span><span class="w">
</span><span class="n">frame</span><span class="o">$</span><span class="n">e1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">serr</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">n1</span><span class="p">,</span><span class="w"> </span><span class="n">deff</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">deff</span><span class="p">,</span><span class="w"> </span><span class="n">rr</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">rr</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="n">frame</span><span class="o">$</span><span class="n">p</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##   strata     N deff   rr   p   n1   e1
## 1      1 10000  1.1 0.80 0.3 2308 0.02
## 2      2  5000  1.0 0.90 0.6 1753 0.02
## 3      3  2000  1.3 0.85 0.1  923 0.02
## 4      4  1000  0.8 0.80 0.2  606 0.02</code></pre></figure> <p>As easy as falling off a log!</p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><category term="survey"/><summary type="html"><![CDATA[Here I show two functions in R to define sample sizes and errors of a proportion, taking into account design effect, response rate, finite population correction, and stratification. They are useful when one needs to do these calculations quickly.]]></summary></entry><entry><title type="html">Cohort component projection</title><link href="https://sdaza.com/blog/2013/projections/" rel="alternate" type="text/html" title="Cohort component projection"/><published>2013-07-02T00:00:00+02:00</published><updated>2013-07-02T00:00:00+02:00</updated><id>https://sdaza.com/blog/2013/projections</id><content type="html" xml:base="https://sdaza.com/blog/2013/projections/"><![CDATA[<p>I present an example of a cohort component projection using a closed female population (Sweden 1993), taken from Preston et al.’s book (Demography 2001, page 125). I use R and basic matrix algebra to replicate their results. The advantage of this procedure is that allows to compute easily the <em>intrinsic growth rate</em> and <em>age-proportionate distribution</em> of the stable equivalent population. All we need is the population by age at time 0 (from a census), survivorship ratios (from a life table), and age-specific fertility rates.</p> <p>The data:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"sweden1993.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">","</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">attach</span><span class="p">(</span><span class="n">dat</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##    age     Nf     Lf      f
## 1    0 293395 497487     NA
## 2    5 248369 497138     NA
## 3   10 240012 496901     NA
## 4   15 261346 496531 0.0120
## 5   20 285209 495902 0.0908
## 6   25 314388 495168 0.1499
## 7   30 281290 494213 0.1125
## 8   35 286923 492760 0.0441
## 9   40 304108 490447 0.0074
## 10  45 324946 486613 0.0003
## 11  50 247613 480665     NA
## 12  55 211351 471786     NA
## 13  60 215140 457852     NA
## 14  65 221764 436153     NA
## 15  70 223506 402775     NA
## 16  75 183654 350358     NA
## 17  80 141990 271512     NA
## 18  85 112424 291707     NA</code></pre></figure> <p>As can be seen, the data have five-year-interval age groups, so each projection forward will involve 5 years. The steps are very simple:</p> <ol> <li>Project forward the population of each age group (estimation of people alive)</li> <li>Calculate the number of births of each age group based on fertility rates, adjusting by mortality (estimation of children alive)</li> <li>Create a Leslie matrix, and then multiple it by the population vector (population by age at time 0)</li> </ol> <h3 id="survivorship-ratios">Survivorship ratios</h3> <p>We have to estimate life table survival ratios, that is, proportions of birth cohorts surviving from one age interval to the next in a <strong>stationary population</strong>. Basically, we are summarizing the mortality experience of different cohorts assuming stationarity. Because census statistics refer to age “last birthday” (rather than exact age), I estimate ratios using $L_x$ (average number of survivors in an age interval) instead of $l_x$.</p> \[S_x = \frac{_5L_x}{_5L_{x-5}}\] <p>I compute the survival ratios using a loop in R. The estimation of the open-ended survival ratio is slightly different but still straightforward:</p> \[\frac{T_{85}}{T_{80}}\] <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">Sf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NA</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">Lf</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">Sf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="n">Lf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># open-ended survival ratio</span><span class="w">
</span><span class="n">Sf</span><span class="p">[</span><span class="nf">length</span><span class="p">(</span><span class="n">Sf</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">18</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">Lf</span><span class="p">[</span><span class="m">17</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">18</span><span class="p">])</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.999 1.000 0.999 0.999 0.999 0.998 0.997 0.995 0.992 0.988 0.982 0.970 0.953 0.923 0.870 0.775 0.518</code></pre></figure> <h3 id="number-of-children">Number of children</h3> <p>This is the tricky part. Because census statistics refer to age “last birthday”, and we are projecting every 5 years, the estimation of the number of person-years lived by women in each age group consists of the average number of women alive at the beginning and end of the period (assuming a linear change over the period). To take advantage of the Leslie matrix, I define the births in R using a loop as follows:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">Bf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">Lf</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">Bf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.05</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Lf</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="m">100000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Sf</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.000000 0.000000 0.014550 0.124596 0.291792 0.318128 0.189858 0.062447 0.009340 0.000364 0.000000 0.000000
## [13] 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000</code></pre></figure> <p>1/(1+1.05) corresponds to a transformation of age-specific fertility rates (son and daughters) to maternity rates (only daughters), assuming that the ratio of male to female births (SBR) is constant across mothers’ ages. The number of births is also adjusted by the corresponding survival ratio from 0 to 5 years old ($\frac{_5L_0}{5 \times l_0}$), the number 5 goes away due to simplifying).</p> <h3 id="leslie-matrix">Leslie matrix</h3> <p>I construct a Leslie matrix by replacing specific cells of a 18 x 18 matrix (18 age groups) by the vectors defined above (survival ratios and maternity rates):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">)</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Bf</span><span class="w">
</span><span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">17</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Sf</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">2</span><span class="o">:</span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">17</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s</span><span class="w">
</span><span class="n">m</span><span class="p">[</span><span class="m">18</span><span class="p">,</span><span class="w"> </span><span class="m">18</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Sf</span><span class="p">[</span><span class="m">17</span><span class="p">]</span></code></pre></figure> <p>Here we have the Leslie matrix:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">##        [,1] [,2]   [,3]  [,4]  [,5]  [,6]  [,7]   [,8]    [,9]    [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18]
##  [1,] 0.000    0 0.0145 0.125 0.292 0.318 0.190 0.0624 0.00934 0.000364 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [2,] 0.999    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [3,] 0.000    1 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [4,] 0.000    0 0.9993 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [5,] 0.000    0 0.0000 0.999 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [6,] 0.000    0 0.0000 0.000 0.999 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [7,] 0.000    0 0.0000 0.000 0.000 0.998 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [8,] 0.000    0 0.0000 0.000 0.000 0.000 0.997 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
##  [9,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.9953 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [10,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.99218 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [11,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.987777 0.000  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [12,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.982  0.00 0.000 0.000  0.00 0.000 0.000 0.000
## [13,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.97 0.000 0.000  0.00 0.000 0.000 0.000
## [14,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.953 0.000  0.00 0.000 0.000 0.000
## [15,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.923  0.00 0.000 0.000 0.000
## [16,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.87 0.000 0.000 0.000
## [17,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.775 0.000 0.000
## [18,] 0.000    0 0.0000 0.000 0.000 0.000 0.000 0.0000 0.00000 0.000000 0.000  0.00 0.000 0.000  0.00 0.000 0.518 0.518</code></pre></figure> <p>Note that the last survival ratio is repeated in the last column (0.518). This is because the estimation of the open-ended survival ratio is:</p> \[(N_{80} + N_{85}) \times \frac{T_{85}}{T_{80}}\] <h3 id="now-lets-do-some-projections">Now, let’s do some projections</h3> <p>Using the R multiplication operator for matrices, I do a 5-year projection by simply multiplying the Leslie matrix by the population vector (remember that matrix multiplication is not commutative).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         [,1]
##  [1,] 293574
##  [2,] 293189
##  [3,] 248251
##  [4,] 239833
##  [5,] 261015
##  [6,] 284787
##  [7,] 313782
##  [8,] 280463
##  [9,] 285576
## [10,] 301731
## [11,] 320974
## [12,] 243039
## [13,] 205109
## [14,] 204944
## [15,] 204793
## [16,] 194419
## [17,] 142324
## [18,] 131768</code></pre></figure> <p>I obtain the same results of the book. Raising this multiplication I can get the projected population of subsequent periods. Because R doesn’t have a power operator for matrices, I define a function called <em>mp</em> to raise matrices (it is not very efficient, but for this example it’s still useful).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">mp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="n">pow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">ans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mat</span><span class="w">
    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="n">pow</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">ans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mat</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">ans</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="nf">return</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure> <p>Let’s project the initial population for two periods (10 years):</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="p">(</span><span class="n">mp</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##         [,1]
##  [1,] 280121
##  [2,] 293368
##  [3,] 293049
##  [4,] 248066
##  [5,] 239529
##  [6,] 260629
##  [7,] 284238
##  [8,] 312859
##  [9,] 279147
## [10,] 283344
## [11,] 298043
## [12,] 315045
## [13,] 235861
## [14,] 195388
## [15,] 189260
## [16,] 178141
## [17,] 150666
## [18,] 141960</code></pre></figure> <p>Again, I get the same result of the book. The nice thing of all this is that estimating eigenvalues and eigenvectors, I can obtain the intrinsic growth rate and age-distribution of the “stable equivalent” population. Using the <em>eigen</em> function in R, I can identify the dominant eigenvalue (higher absolute number), and the corresponding eigenvector:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eigen</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="w">

</span><span class="c1"># intrinsic growth rate</span><span class="w">
</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">values</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">/</span><span class="m">5</span><span class="w">  </span><span class="c1"># 5-year-projection</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.000223</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># intrinsic proportionate age distribution</span><span class="w">
</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">vector</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">e</span><span class="o">$</span><span class="n">vector</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">]))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##  [1] 0.0619 0.0618 0.0617 0.0616 0.0614 0.0613 0.0611 0.0608 0.0605 0.0600 0.0592 0.0580 0.0562 0.0535 0.0494 0.0429
## [17] 0.0332 0.0356</code></pre></figure> <p>The population is growing but little.</p> <h3 id="what-about-the-population-momentum">What about the population momentum?</h3> <p>The population momentum corresponds to the growth of a population after imposing replacement fertility conditions, that is, NRR=1. Thus, the first thing we have to do is to estimate NRR.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># calculating NRR</span><span class="w">
</span><span class="p">(</span><span class="n">NRR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">f</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Lf</span><span class="o">/</span><span class="m">100000</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.05</span><span class="p">)),</span><span class="w"> </span><span class="n">na.rm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1.01</code></pre></figure> <p>We can quickly estimate the intrinsic growth rate using NRR:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># quick estimation of the intrinsic growth rate</span><span class="w">
</span><span class="nf">log</span><span class="p">(</span><span class="n">NRR</span><span class="p">)</span><span class="o">/</span><span class="m">27</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 0.000237</code></pre></figure> <p>Very close to our estimation using cohort component projection. To impose the replacement condition, I just have to divide the first row of the Leslie matrix by NRR.</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">m</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="o">/</span><span class="n">NRR</span></code></pre></figure> <p>To get the population momentum we have to project the initial population until the growth is zero (here I raised the matrix 100 times), and then to compute the ratio between the initial population and the non-growing population (stationary).</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># population momentum</span><span class="w">
</span><span class="nf">sum</span><span class="p">(</span><span class="n">mp</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Nf</span><span class="p">)</span><span class="o">/</span><span class="nf">sum</span><span class="p">(</span><span class="n">Nf</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] 1.01</code></pre></figure> <p>After imposing the replacement condition, the population grew 1%.</p>]]></content><author><name>Sebastian Daza</name></author><category term="demography"/><summary type="html"><![CDATA[A simple example using R and matrices]]></summary></entry><entry><title type="html">Looking for variables in R</title><link href="https://sdaza.com/blog/2013/lookvar/" rel="alternate" type="text/html" title="Looking for variables in R"/><published>2013-01-29T00:00:00+01:00</published><updated>2013-01-29T00:00:00+01:00</updated><id>https://sdaza.com/blog/2013/lookvar</id><content type="html" xml:base="https://sdaza.com/blog/2013/lookvar/"><![CDATA[<p>Recently, I have been working with big databases. After reading their codebooks (usually very long pdf files), I thought it would be useful to have a function to find variable names in R. I wrote a simply function that looks for variable names in <strong>data.frame</strong> and <strong>data.table</strong> objects.</p> <p>Here an example:</p> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">devtools</span><span class="p">);</span><span class="w"> </span><span class="n">source_gist</span><span class="p">(</span><span class="s2">"4661324"</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">dat</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.table</span><span class="p">(</span><span class="n">infert</span><span class="p">)</span><span class="w">
</span><span class="p">(</span><span class="n">var</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lookvar</span><span class="p">(</span><span class="n">dat</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"par"</span><span class="p">,</span><span class="w"> </span><span class="s2">"spon"</span><span class="p">)))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">## [1] "parity"      "spontaneous"</code></pre></figure> <figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">dat</span><span class="p">[,</span><span class="w"> </span><span class="n">var</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">]</span></code></pre></figure> <figure class="highlight"><pre><code class="language-text" data-lang="text">##      parity spontaneous
##   1:      6           2
##   2:      1           0
##   3:      6           0
##   4:      4           0
##   5:      3           1
##  ---
## 244:      1           1
## 245:      1           0
## 246:      2           0
## 247:      1           1
## 248:      1           1</code></pre></figure> <p>Pretty useful, at least for me. You can also use <em>regular expressions</em> to get variables, for instance, something like <code class="language-plaintext highlighter-rouge">lookvar(dat, "p5[0-2]_[a-z]+_2")</code>.</p>]]></content><author><name>Sebastian Daza</name></author><category term="R"/><summary type="html"><![CDATA[Recently, I have been working with big databases. After reading their codebooks (usually very long pdf files), I thought it would be useful to have a function to find variable names in R. I wrote a simply function that looks for variable names in data.frame and data.table objects.]]></summary></entry></feed>